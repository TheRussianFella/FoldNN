{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    with open(path) as f:\n",
    "        a = f.readlines()\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(dir_path):\n",
    "    data = []\n",
    "    \n",
    "    for f in set(list(map(lambda x: \".\".join(x.split('.')[:-1]), os.listdir(dir_path)))):\n",
    "        dssp = read_file(os.path.join(dir_path, f+\".dssp\"))[1].strip(\"\\n\")\n",
    "        fasta = read_file(os.path.join(dir_path, f+\".fasta\"))[1].strip(\"\\n\")\n",
    "        data.append([fasta, dssp])\n",
    "        \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = load_data(\"train/\")\n",
    "\n",
    "test = load_data(\"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'VSKDLDYISTANHDQPPRHLGSRFSAEGEFLPEPGNTVVCHLVEGSQTESAIVSTRQRFLDMPEASQLAFTPVSSLHMTVFQGVIESRRALPYWPQTLPLDTPIDAVTDYYRDRLSTFPTLPAFNMRVTGLRPVGMVMKGATAEDDSIVALWRDTFADFFGYRHPDHDTYEFHITLSYIVSWFEPECLPRWQAMLDEELEKLRVAAPVIQMRPPAFCEFKDMNHFKELVVFD',\n",
       "       '--------E----------E---E-----E----EEEEEEEE----HHHHHHHHHHHHHH-------EEE------EEEEEEEEE------------------HHHHHHHHHHH-----------EEEEEEE--EEEEEE--HHHHHHHHHHHHHHHHHH-----------EEEE-EEE---E----HHHHHHHHHHHHHHHHHH-----E---EEEEE------EEEEE--'],\n",
       "      dtype='<U759')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#acid_table = list(np.unique(list(\"\".join(train[:,0]))))\n",
    "\n",
    "#class_table = list(np.unique(list(\"\".join(train[:,1]))))\n",
    "\n",
    "acid_table = list(np.load('acid.npz.npy'))\n",
    "class_table = list(np.load('class.npz.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('acid.npz', np.array(acid_table))\n",
    "np.save('class.npz', np.array(class_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_data(data, acid_table, class_table):\n",
    "    \n",
    "    acid_code = lambda x: np.array([acid_table.index(y) for y in x])\n",
    "    class_code = lambda x: np.array([class_table.index(y) + 1 for y in x])\n",
    "    \n",
    "    return np.array(list(map(lambda x: [acid_code(x[0]), class_code(x[1])], data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = translate_data(train, acid_table, class_table)\n",
    "\n",
    "test = translate_data(test, acid_table, class_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ array([ 3, 11,  9,  3,  2, 16,  4,  9,  8, 10, 17,  8, 17,  9, 14,  0,  3,\n",
       "       14,  3,  4,  9,  3,  3,  3,  0, 13,  8,  9, 20,  8,  3, 17,  8,  8,\n",
       "        5, 11,  1,  9,  2, 17,  8,  8,  9,  8,  3,  8, 12,  9,  0,  9, 13,\n",
       "       14, 14, 17,  7, 14,  8,  4,  7,  5,  3,  8,  2, 20,  3,  8, 17,  3,\n",
       "        9, 17, 14, 15,  9,  9,  3,  8,  5,  5,  3, 17, 11,  9,  5,  8,  5,\n",
       "        8, 17,  9,  8, 14,  8,  3, 14, 18,  9]),\n",
       "       array([1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 1, 2, 2, 1, 3, 3, 3, 3, 1, 1, 1,\n",
       "       1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2,\n",
       "       2, 2, 1])], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_seq(seq, maxlen, stride):\n",
    "    seq_len = seq.shape[0]\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    if seq_len < maxlen:\n",
    "        temp.append(seq)\n",
    "        \n",
    "    else:\n",
    "        full_batches = seq_len // maxlen\n",
    "\n",
    "        for i in range(full_batches):\n",
    "            idx = slice(i * maxlen, (i+1) * maxlen)\n",
    "            temp.append(seq[idx])\n",
    "        \n",
    "        elements_left = seq_len % maxlen\n",
    "        \n",
    "        if elements_left:\n",
    "            start_element = elements_left + stride\n",
    "            \n",
    "            if start_element > maxlen:\n",
    "                start_element = maxlen\n",
    "                \n",
    "            temp.append(seq[-start_element:])\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  9,  7, 17, 12, 20, 11,  9, 12,  9, 12,  5,  5, 17, 17, 12, 14,\n",
       "       10,  9,  7, 16,  7,  9,  5, 16, 17,  8, 12, 11,  0, 11, 14,  7,  0,\n",
       "        9,  2,  4, 13, 14,  5, 11,  2, 17,  0,  4,  6,  4, 11, 12, 14,  4,\n",
       "       11,  3, 11, 11, 14, 14, 17,  7, 17,  1, 11, 16,  8,  9,  2, 11, 11,\n",
       "       18,  5, 14,  3,  3, 14, 13, 15, 17,  4, 12,  4,  3, 15,  5,  8, 12,\n",
       "        4,  8,  7, 13, 17,  9, 17,  3, 12,  2,  6,  4,  8, 17,  0, 17, 11,\n",
       "        2,  0,  6,  9,  9, 13, 20, 11,  6, 14, 17,  8,  8,  9, 11,  3,  7,\n",
       "       15,  8,  9,  5,  7, 15,  5,  2,  7,  2,  9, 16, 15,  0, 15, 20, 16,\n",
       "       10,  7])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_pair_seq(pair_seq, maxlen, stride):\n",
    "        \n",
    "    assert pair_seq[0].shape == pair_seq[1].shape\n",
    "\n",
    "    return list(map(list, zip(split_seq(pair_seq[0], maxlen, stride), split_seq(pair_seq[1], maxlen, stride))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_prediction(part_predictions, original_length, stride):\n",
    "    max_len = part_predictions.shape[1]\n",
    "    \n",
    "    final_prediction = []\n",
    "    \n",
    "    if len(part_predictions) != 1:\n",
    "        final_prediction = np.concatenate(part_predictions[:-1], axis=0)\n",
    "\n",
    "    el_left = original_length % max_len\n",
    "    start_element = stride\n",
    "    \n",
    "    if el_left + stride > max_len:\n",
    "        start_element = max_len - el_left\n",
    "\n",
    "    final_part_prediction = part_predictions[-1][start_element:start_element + el_left]\n",
    "\n",
    "    final_prediction = np.concatenate([final_prediction, final_part_prediction], axis=0)\n",
    "    \n",
    "    return final_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(x, session, method, maxlen=400, stride=100):\n",
    "    prepared = []; idx = []; original_len = []; model_len = []\n",
    "    \n",
    "    curr_idx = 0\n",
    "    \n",
    "    for seq in x:\n",
    "        original_len.append(len(seq))\n",
    "        \n",
    "        splited = split_seq(seq, maxlen, stride)\n",
    "        \n",
    "        model_len.extend(list(map(len, splited)))\n",
    "        splited = sequence.pad_sequences(splited, maxlen, value=-1, padding=\"post\")\n",
    "        \n",
    "        prepared.extend(splited)\n",
    "        idx.append([curr_idx, curr_idx+len(splited)])\n",
    "        curr_idx += len(splited)\n",
    "    \n",
    "    predictions = session.run(method, feed_dict={\n",
    "        x_raw: np.array(prepared),\n",
    "        seq_len: np.array(model_len)\n",
    "    })\n",
    "    \n",
    "    final_predictions = []\n",
    "    for i, seq_idx in enumerate(idx):\n",
    "        seq_predictions = predictions[slice(seq_idx[0], seq_idx[1])]\n",
    "\n",
    "        final_predictions.append(build_prediction(seq_predictions, original_len[i], stride))\n",
    "        \n",
    "    return np.array(list(map(lambda x:make_pred(x, len(x), class_table), final_predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(x, y, session, method, maxlen=400, stride=100):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = tf.InteractiveSession(); s.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = predict(test[:10, 0], s, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def to_normal(seq, seq_len, table):\n",
    "    #print(seq)\n",
    "    return \"\".join(list(map(lambda x: table[int(x)], seq)))[:seq_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_pred(pred_raw, seq_len, table):\n",
    "    pred = pred_raw - 1\n",
    "    pred = np.array(list(map(lambda x: 0 if x == -1 else x, pred)))\n",
    "    return to_normal(pred, seq_len, table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dynamic_iter(data, batchsize, maxlen=300, stride=100, shuffle=True):\n",
    "    \n",
    "    splited = list(map(lambda x: split_pair_seq(x, maxlen, stride), data))\n",
    "    \n",
    "    prep_data = []\n",
    "    \n",
    "    for seq in splited:\n",
    "        prep_data.extend(seq)\n",
    "    \n",
    "    prep_data = np.array(prep_data)\n",
    "    \n",
    "    # Batching\n",
    "    index = list(range(len(prep_data)))\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.shuffle(index)\n",
    "    for i in range(0, len(prep_data) - batchsize + 1, batchsize):\n",
    "        \n",
    "        x = prep_data[index[i:i+batchsize], 0]\n",
    "        y = prep_data[index[i:i+batchsize], 1]\n",
    "\n",
    "        seq_len = np.array(list(map(lambda z: 400 if len(z) > 400 else len(z), x)), dtype=\"int32\")\n",
    "        \n",
    "        x = sequence.pad_sequences(x, padding=\"post\", value=-1, maxlen=maxlen)\n",
    "        y = sequence.pad_sequences(y, padding=\"post\", maxlen=maxlen)\n",
    "        \n",
    "        yield x, y, seq_len\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_class = len(acid_table)\n",
    "output_class = len(class_table) + 1 # plus one for padding\n",
    "\n",
    "learning_rate = 0.01\n",
    "seq_max_len = 400\n",
    "n_units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_raw = tf.placeholder(tf.int32, [None, seq_max_len], name=\"x_raw\")\n",
    "y_raw = tf.placeholder(tf.int32, [None, seq_max_len], name=\"y_raw\")\n",
    "seq_len = tf.placeholder(tf.int32, [None], name=\"seq_len\")\n",
    "\n",
    "x = tf.one_hot(x_raw, input_class, dtype=tf.float32, name=\"one_hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  6  6  6 10 17 10  3 20  3  9 14 16 12  9 17  8  2 13  7  9  8  9  8 17\n",
      "  5  2 17 17 20  7 16  5  3  7  4 16  0 14  2  3  0  6  0 14  0  9  3 18 10\n",
      "  3  3  5  8  3  9 12  4 15  4  2  8  5 17 17 20  6  1  5 12  9 17  8  8 11\n",
      "  2  3 18 14 17 17 15  0  5 12 16 16 15  0 14 10 11 12  4 16 12  8  7  9  3\n",
      "  8 17  3  1 10  5  7  7  5  8  5  5 10 15  3  3 17 17  3  0 10 14  5  8  0\n",
      "  0 20  4  0  4 16  5  5  0  5  0  9  0  0 10 15  7  8  8 17  8  5 17 17 18\n",
      "  3  2  9  5 10 12  3  0 17 18  9  9  3 17  3 14  4  5 12  1  7 17  0  7  2\n",
      "  0  6  5 11 15  9 20 14 14 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[16  3  3 13  8 14 10  9  9  9 12  0  3  0 17 11 17 15 14  8  5  3  4 16  9\n",
      "  8 17  5  5 15  9  8  5  0  8 11 17 20 20 11 10  0  9 10 11  0  5 17  8  8\n",
      " 17 17 17 14  4  2 12 13 13  9  6 15 16 17 20  1 20 16  9  2  5 14  4  7  1\n",
      "  3  0  3  1  9 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[18 15  0 16 11  3  3  2  2  9 15 17  3  0  3  7  0  6 13  7  0  3 15  4 15\n",
      "  8  8 20  8  4 12 15 14 15 15  5  7  4  9 20 11  4  3 13  9  8 10 11  9  2\n",
      "  2  7 17  8  3  0  8 11 17 12  5 17 16 14  9  0  6  2  5 15  8  7 12  9 14\n",
      "  1 17  9  5 18 17  0  9  0 11 15  8  8  4 13  9  9 17  3  0  2  8  9 15  8\n",
      "  7 10 13  2  2  9 11 14 20 16 15 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[ 3 15  9  7 20  9  9 13 12  5  8  6 14  9  6 17 10  3  5  2 18  1  5  9  7\n",
      " 12 17  5 13 12  1 10 13 17 16 16 16  5  9  8 18 11  9 16 11  2 17  9  0  4\n",
      "  5 16  9 17 15 16 15 11 16 20  2  5 15  5 17 17 16 17  3 16  2  6 12  9  9\n",
      " 18 16 10  0  7  8 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[ 9  7 16  2 16  9 15 12 13  0  4  3  3  0  9 14  0  8  5  2  4 20  6  7  6\n",
      "  6 12 20  6  7  0 10  6 11  5 11  0 16 14  3 13  7 13  5 18 17  0 11 14  4\n",
      " 20 20 13 16 16  7 12  9  8  2  0  0  7 10  0 11  1 12  2  0 13 16 14 14  8\n",
      " 18 17 13 14  7  9  2  6  2  5 15  6  5  3  2  5  5  7  3  0 18  9 14  9  5\n",
      "  3  0 17  5  9 15 14  2  2  9  9 15  3 14  6 17  9 12  5 17 14  4  0 17  2\n",
      "  0 20  9 11  4  0 14 14  0  1 18 13  3  0  0  1 15 15  9 16  3  9  4  0 12\n",
      " 13  7  6 13 15 14  9  2 15 18 12 13  6 20 12 18  7  8  3  3  5 20  4  4  4\n",
      " 14 15 14  9 15 13  0 11 14  2 17  3  6  5  9  0  9  0  8  0 20  1  2 15  0\n",
      "  3  8 13 11 14 10  9  3  7  9 13  4  8  9  2  7  9 18 15 10  9  2  0 10 16\n",
      " 10  0 20  0  9 13 14 12 12 20  6 16 17 16  2  8  0  0 18  6 16 16 14  9 17\n",
      "  9  3  6  6 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[ 6 16  8  4  3  0 15 17 20 17  9  8  8  3  3  5  5 14  6 16  5  4  4 15  5\n",
      " 20 14 12 13  4 20  4 14 16 16  2 17 16  5 17 17 13  9 12 12  5 17  3 10 17\n",
      " 10 12  5  2 11 17 16  4 16 17  3  9  7  8 12 17  0  9  3  3  5  9 14  4  0\n",
      "  7 14  3  5  5 14 16 17  5  0  5 17 17 16  8  7  9  3 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[ 0  4 11 13 16  3  4 11  8  9  9  9  3  1 17 17  8 16 13 15 15 17  0  8  7\n",
      "  9  5  7  3 15  9 15 12  6 17 15  5 11 15  8  4  3 20  0 11 10 17  3  2  7\n",
      " 14  3  8 17 15 15  3 10  3 14  4  4 12  8 11  2  2  3 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[17  2  0  3  0 17 17 13 13  8  1  7 15  1  6  5  5  2  9 16  5  0 15  0 12\n",
      "  0  7  2  8  0  5  0 11 20 15  3  3  3  7  9  2  7  7  9 11  5 13  5  5 10\n",
      " 12  5  5  7  0  8  5  0  3  0  3  0 17  0  0 18  9  0  3  8  8 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[ 3  3  3 16 14  3  9 13 15  9  0  0  0 17 17 12 15  0 13 16  9  8  7 16  2\n",
      "  4 15  4 15  2  4  3  9 15  2  9  3 16  0  9  1 16  7 14 10  4 16  2  9 11\n",
      "  9 17 13 11  4 13 10  8  6  3 17  9  1 14 18  7  9 15 17  8  8 11 20 14  8\n",
      " 11 17  0 20  6 11 18 14  6  0  4 11 16  0 13  1 10  4  0  0  9  8  0  5  8\n",
      "  7 13 11  8  9 16  2  9  3  7  9  0  9  9  7  0  0  9 15  6  2  9  2  6 12\n",
      "  5 17 15 11 13  4  9  7 11 16 11 15  3  9  0  9 10 20 11  2  3 15 17  9  3\n",
      "  6  6  6  4  2 13  1  9 10  7  9 11 15 12  5 11 13  7  9 15  5  9 15  7  3\n",
      "  3 20  8 16 16  9  8  7  7  8 13  0  7  9  0 16  2  9  0  9 20  7  8 14 14\n",
      "  5  3  4  4  3  9  7 14  8 11 13  4 11  9  3  2 12  6 13  8  3  9  4  9  0\n",
      " 10  9 10 16  0  1  2  9 15  0  7 16  8 12 18 12  7 13 13 14  7  0  3  9 17\n",
      "  0 16  3  4  4  2 13  5  2 14  3 14  8  3  9 11  7  3 12 16  2  9 10 11 14\n",
      "  3  8  8 11  8  7 12 15 10 13 17  5  4  7  2  0  7  1  9 13  9 20  3  0  9]\n",
      "[12  7  1 16 11  1  1  0  5 20  8  5  1 11 20 20 15  0 11  5  0  4  7  1  3\n",
      "  5 13 15  2 12  8  8 12  8  0  1 12  9 11  1  2 12  6  7  0 20 15  8  1 12\n",
      " 14 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[17 17 11  9  0 15 14 11  0  5  4  7 11  8 14  4  2  5 17  9  0 15  3  9  0\n",
      "  2 12 13  9 20  8 16  4 16  2  0  0  3 17  7  5  3  0 18  3 15 14  3  4  5\n",
      "  8  0 17 14  3  7 10  0  9  0  2  9  0 11 14 20 17  2  3 13  0 12 18 17 17\n",
      "  0  8 13  3  5 14  2  0  2  9 13  0  7  1 15 10  5  7 11  9  4 14 17  9 10\n",
      " 16 20  9  8 12 17  9 12  8  9 16  3 14  0  3  0  4  9 11 16  3  9 16 18  2\n",
      "  5  7 13 13 12  9  9  5  6  8 17 11 12  4  8  0  9 20 11 14  7  2 10 14 13\n",
      " 17  3  0  9 17  3  0 15  8  3  3 17 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[16  4 16 15  4 13  9  3  3  9  3  8  0  4 15 14 16  6 20 12  2 17  4 16 14\n",
      "  3  3  9  0 10  8  7  5  9 16  3  0 14  7 13 17 18  4 13 11 14 14  0  8 18\n",
      " 14 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[12 12  5 16  9 17 20 16  5  8 20 14  3  2  4  3  7  3 17 10 11 20 15  7  3\n",
      "  3  4 14  3  4  8 16 16  2 17  3 15 17  9 12  4 14  2 15 15 16 12 16 18  7\n",
      " 11  7 16  5  7  6 14 16  2 17 17 13 14 17  5  3  4  4  5 16  6 12  9 17  9\n",
      "  3  2  7  9 11 17  6 13 14 12  8 17  3  4  4  3 11 20 17  4  7 17  9  8 10\n",
      "  4 16 20  2  8  6  3  9  3 15  3 13 17 15  9  7  9 16  8 11  1 17  9 10  4\n",
      " 13  3  8  7  5  2 17  4  2 12 17 14  3 14  7 14 20 11 14  5  7  7 14  8  8\n",
      " 14  0  2 20  9  9 20 15  9  7  2  0  9 17  2  2 20  4 17  9  9  3  8  7  2\n",
      "  2  3  7  2 17  9  3  3  3 17 16 17 13 14 16  6 13  9  8 14 11  9 17  3  9\n",
      " 14  8 16  7 18 12  9 14  3 17  9 15 15  9 20 14  2 17 12 12  9  7  3 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[11 16  2  5  9  0  5  4 12 14 20  8 17  0 11  7 13 13 17 13 13 13  7  8 15\n",
      " 15  5  1  0 17 20  4  4  0 20 12  9 16  2  3 12  1  4  9 17  2  9 13  0  9\n",
      " 16  5 13 13  7 16  3  7 12 11 12 20 20  5  8 20  0  5 12  9  5 13  7 13 16\n",
      "  7  8  5 17  5 12 11  5 16  7  4  0  4 15  2 17  1 17  6  9  5  1 13  9 12\n",
      "  0 13 17  7 17 15 15  3 15  2 12  5  9 20  0  8  5  0  2  9  6  1 12  1  6\n",
      "  5 15  7 20  0  9  8  2  5  5 17 17 17 15  5 12  0 12 14 12  9 12  7 17  7\n",
      "  9  2 20  2 15 15 16  5  2  7 20  0 17  5 16 11  0 12 20  4 15  0  5  7 12\n",
      " 14 16 16 12 13  2 11  9  9 20  2 12 14 20 15 20 15 17 12 11 11 12 15  1 15\n",
      " 11  5 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[ 9  8  8 15  9 11 17  0  8 15  3  4  2 14  2  0  0 10 13 14  8  9  3  8 10\n",
      "  0  2 13  0 10 16 13 10 20  8 13  0 14 15  3  2  8 14  0  8 17 16 15  0 10\n",
      " 13 16 10  9  4 16 10  9 14  8  9  2 11  2  0  9 11 11  7  7 11 11  0 14  2\n",
      "  5  1 17 12  9 11  7  7 12  9 16 16  0  0  8  9 10 17 17 17 12  2 20  5 16\n",
      " 20  8 11 16  1  2  5 11 16  4 16 20  0 15  0  9 18  3  7 13 13 17 17  2  0\n",
      "  2 15  8  7 17 13  9 15  3  7 11 10  2 11 15 12 11  9  0 18 12  9  7 17 16\n",
      "  0  9 14  0 11 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[15  0 16 12  6  9  2  0 17  3 13 16  9 14 13 17 15 12  5  9  3  5  2 17 18\n",
      "  3 14 16 15  5 11  8  9  2  5 15  0  0  2 12 15  2 18  9  9 13 16 12  5  1\n",
      " 18  5  2  2  8  1  0  2 14 17  5 16  8 14  9  9  0  8 10 16  3 11  7  5 11\n",
      "  0 16 14 16 17  2  7 15 16  9  0 12  4 12 11  5  0  4 13  2  0  7 17  0  5\n",
      "  9  8  3 15  0  0  8  5 11  8  9  8 17 14  7  9 17  5  0  0 12  6 10 11 17\n",
      "  7 12 15  8 20 14  2  3  9 16  0  8  9  5  8  0  0  3 11  7 16  9 11 17  0\n",
      " 15 10 16 16 15  8 16  0  4 15 18 11  6 15  8  7  9 17 17  2  5 13 15  0  9\n",
      " 16  5  5  7 11 15 18  8  2  2 20  9  2 16 16  6 12 17 15  2 17  2  9  0  9\n",
      " 16  5 12  0  0  5 15  0  5 14 20  9  2 16  9 18 16 18 16  1 13 11  8 15 11\n",
      "  7  0 15 17 18  4  0  0 15  5 11  0  5  1 10 12 16 10  6  8  2 16 11 12  8\n",
      "  0 15 12  0 16  5 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "for a, b, c in dynamic_iter(test, 10):\n",
    "    print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell(reuse=tf.get_variable_scope().reuse):\n",
    "    cell = tf.contrib.rnn.NASCell(n_units, reuse=reuse)\n",
    "    return tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw_cell = lstm_cell(); bw_cell = lstm_cell()\n",
    "\n",
    "output, state = tf.nn.bidirectional_dynamic_rnn(fw_cell, bw_cell, x, seq_len, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con_out = tf.concat(output, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten = tf.reshape(con_out, [-1, 2 * n_units * seq_max_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"out\" : tf.Variable(tf.truncated_normal(shape=[2 * n_units * seq_max_len, output_class * seq_max_len], stddev=0.1))\n",
    "}\n",
    "bias = {\n",
    "    \"out\" : tf.Variable(tf.truncated_normal(shape=[output_class * seq_max_len]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_logits = tf.matmul(flatten, weights[\"out\"]) + bias[\"out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = tf.reshape(flat_logits, shape=[-1, seq_max_len, output_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_raw, logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = tf.to_float(tf.not_equal(y_raw, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_loss = loss * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_loss = tf.reduce_mean(tf.reduce_sum(norm_loss) / tf.to_float(seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.arg_max(tf.nn.softmax(logits), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 50\n",
    "disp_batch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10\n",
      "Example: \n",
      "Real: HHHHHHHHHHHHHHHHH---HHHHHHH----HHHHHHH-----E----E----------HHHHHHHEEEEE---------EEEEE-----EEEE-HHHHHHH--------HHHHHHHHHHHHHH-E-HHHHHHHHHHHHHHHH------------HHHHHHHHHHHH---HHHHHHH---HHHHHHHH-------EE--EE---------HHHHHHHHH------------HHHHH-------------HHHHHHHHHHHHH--HHHHH----HHHHHH-----HHHHHHHHHH-----HHHHHHHHHHHHHHHHHHHHHH--------------HHHH--------------HHHHHHHHHHHHHHH-E-----E-HHHHHH-----HHHHHH------\n",
      "Predicted: ---HEHHHH-H-H-HH--HH----E------HHHHH---H-------H-HH-HHHH-EHHHHE---E-------H-H-H------------HH---HHHH---H--------------EE-----HHHHHHHEH------EEE-H------------HHEEEEEE---E-E---------EEHHHHH---H-HHHH--HH--H-E-----HHHHHHHHHHEEH----------H-H--E--H-HHHHHHH-------HH-HHHHHHHHHHHH---EEEHE-----------HH--H---------E-E-----EE-----HHHH-EE--EE---E---EE-------HHHHHHHHHHH-EH--------------------HHHHHHHHHHHHHHH----\n",
      "Loss: 85.3606\n",
      "Batch 20\n",
      "Example: \n",
      "Real: ------------EEEE------EEEEEE----EEEEE-----EEEEEEE--EEE----EEEEE--EEEEEE----EEEEEEE\n",
      "Predicted: -----EHH-HHH-HHHH--HHHHHH--HHEHHHHEH--E-H------E-H-H-EE-H-HHEH--H---H-H--HHH--H--H\n",
      "Loss: 76.6338\n",
      "Epoch 0 done! Average loss: 1.0\n",
      "Batch 10\n",
      "Example: \n",
      "Real: ---HHHHHHHHHHHHHHHHHH---------HHHHHHHHH-------HHHHHHHE-------HHHHHHHH-------------------\n",
      "Predicted: -----HHHHHHH-H---HH-----------HHHHHHH---H--H--------H---------------HH------------------\n",
      "Loss: 58.2848\n",
      "Batch 20\n",
      "Example: \n",
      "Real: ---HHHHHHHHHH-------EEE----HHHHHH---HHHHHHHHH---EEE--------HHHHHHHHHHH-------------HHHH--HHHHHHHHHHHHHHHHHHHHH-----HHHHHHHHHHH-------HHHHHHHH--\n",
      "Predicted: ----HHHHHHHHHH------EHHH-HHHHHHHH---HHHHHHHHH-HHHHE--------HHHHHHHHH-H------------HHH----HHHHHHHHHHHHHHHHHHHHH-------HHH-HHHHHHHHH-HHHHHHHHHH--\n",
      "Loss: 59.1449\n",
      "Epoch 1 done! Average loss: 1.0\n",
      "Batch 10\n",
      "Example: \n",
      "Real: ---EEEEEEE-----HHHHHHH------HHHHHHHHH---EEEEEEE--EEEEEEE-----HHHHHH------EEEEHHHHHHHHHHHH----------HHHHHHHHHHHHHHHHH----HHHHHHHHHHHHHHHHHHHH---\n",
      "Predicted: ---HHHHHHHHHHHHHHHHHHH------HHHHHHHHH-HHHHHHHHHHHHH-H-HHH-HH-HHHHH--H-------HHHHHHHHHHHHH------H-HHHHHHHHHHHHHHHHHHHH--HHHHHHHHHHHHHHHHHHHHHH--\n",
      "Loss: 19.2511\n",
      "Batch 20\n",
      "Example: \n",
      "Real: -EEEEE--EEEEE------HHHHHHHHHHHHHHHHHHH-------HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH-\n",
      "Predicted: ---HHHHH-HHHE------HHHHHHH-HHHHHH---H-----HH-HHHHHHHHHHHHHHHHHHHHHH-H-HHH---H-HHHHHHHHH---H-\n",
      "Loss: 26.752\n",
      "Epoch 2 done! Average loss: 1.0\n",
      "Batch 10\n",
      "Example: \n",
      "Real: ----HHHHH------------E--------HHHHHHHHHHHHHHHHH----E-HHHHHHHHH----------HHHHHHHHHHHH--EEEEE-----HHHHHHHHH--EEEEE----------------HHHHHHHH------HHHHHHHHHHHH-HHHHHH---HHHHHHHHHH-----EE------EE--HHHH----HHHHHHH----EEEE--HHHHH-E---------EEEEE--HHHHHHH-----HHHHHHHH----E----------E-\n",
      "Predicted: ----HHHHH------------E--------HHHHHHHHHHHHHHHHH----E-HHHHHHHHH----------HHHHHHHHHHHH--EEEEE-----HHHHHHHHH--EEEEE----------------HHHHHHHH------HHHHHHHHHHHH-HHHHHH---HHHHHHHHHH-----EE------EE--HHHH----HHHHHHH----EEEE--HHHHH-E---------EEEEE--HHHHHHH-----HHHHHHHH----E----------E-\n",
      "Loss: 8.7099\n",
      "Batch 20\n",
      "Example: \n",
      "Real: ---------EEEEEEEEEEE--EEEEEEEEEEEE----EEEEEEEE---------------------E---------HHHH-----EEEEEEEEE----EEEEEEEEEEE--EEEEEEEEEEE------------E-------EEEEEEE----EEEEEEEEEEEE----EEEEEEEEEEEE-----------EEEEEEEEEE--------EEEEEEEEEEE----\n",
      "Predicted: ---------EEEEEEEEEEE--EEEEEEEEEEEE----EEEEEEEE---------------------E---------HHHH-----EEEEEEEEE----EEEEEEEEEEE--EEEEEEEEEEE------------E-------EEEEEEE----EEEEEEEEEEEE----EEEEEEEEEEEE-----------EEEEEEEEEE--------EEEEEEEEEEE----\n",
      "Loss: 6.81733\n",
      "Epoch 3 done! Average loss: 1.0\n",
      "Batch 10\n",
      "Example: \n",
      "Real: -EE--------HHHHHHHHHHHHHHHHHHHHHHHH-HHHHH--\n",
      "Predicted: -EE--------HHHHHHHHHHHHHHHHHHHHHHHH-H------\n",
      "Loss: 2.87282\n",
      "Batch 20\n",
      "Example: \n",
      "Real: -EEEE---E---E----EEE--HHHHHH-------EEE--HHHHHHHHHHH-\n",
      "Predicted: -EEEE---E---E----EEE--HHHHHH-------EEE--HHHHHHHHHHH-\n",
      "Loss: 2.18713\n",
      "Epoch 4 done! Average loss: 1.0\n",
      "Batch 10\n",
      "Example: \n",
      "Real: --EEEEEEEEE----HHHHHHHHHHH------EEEE----EEEEE-HHHHHHHHHHHHHHHH-----EEEEEEEEE--------------------------E--EEEEEEE-----HHHHHHHHHHHHHH---EEEEE--EEEE--EHHHHHHHHHHHHHHHHHH---EEEEEEEEE--------\n",
      "Predicted: --EEEEEEEEE----HHHHHHHHHHH------EEEE----EEEEE-HHHHHHHHHHHHHHHH-----EEEEEEEEE--------------------------E--EEEEEEE-----HHHHHHHHHHHHHH---EEEEE--EEEE--EHHHHHHHHHHHHHHHHHH---EEEEEEEEE--------\n",
      "Loss: 0.572934\n",
      "Batch 20\n",
      "Example: \n",
      "Real: -----EEEEEE--EEEEEE--EEEEEE-----EEEEE----EEEEEEE-----EEEEEEEE-----EEEEEEEE----EEEE-----EEEE--EE--EEEEE-----EEEEE----------EEEEEE----EEEE-------EEEEE--EEEEEE-----------------EEEEEEE--EEEEEE------EEEEEE--EEEEEE------EEEEEE------EE--------EEEEEE----EEEEE--EEEEE------EEE-------E---EEE\n",
      "Predicted: -----EEEEEE--EEEEEE--EEEEEE-----EEEEE----EEEEEEE-----EEEEEEEE-----EEEEEEEE----EEEE-----EEEE--EE--EEEEE-----EEEEE----------EEEEEE----EEEE-------EEEEE--EEEEEE-----------------EEEEEEE--EEEEEE------EEEEEE--EEEEEE------EEEEEE------EE--------EEEEEE----EEEEE--EEEEE------EEE-------E---EEE\n",
      "Loss: 0.44864\n",
      "Epoch 5 done! Average loss: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-b4040296f83a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mx_raw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0my_raw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mseq_len\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             })\n\u001b[1;32m     14\u001b[0m             \u001b[0mnum_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/max/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/max/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/max/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/max/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/max/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        avg_loss = 0.; num_iter = 0\n",
    "        for x_batch, y_batch, len_batch in dynamic_iter(train, batch_size, maxlen=seq_max_len):\n",
    "            \n",
    "            _, c = sess.run([train_step, mean_loss], feed_dict={\n",
    "                x_raw: x_batch,\n",
    "                y_raw: y_batch,\n",
    "                seq_len: len_batch\n",
    "            })\n",
    "            \n",
    "            num_iter += 1; avg_loss += c\n",
    "            \n",
    "            if num_iter % disp_batch == 0:\n",
    "                \n",
    "                prediction = sess.run(pred, feed_dict={\n",
    "            \n",
    "                x_raw: x_batch[:1], y_raw: y_batch[:1], seq_len: len_batch[:1] \n",
    "                    \n",
    "                })\n",
    "                \n",
    "                print(\"Batch {}\".format(num_iter))\n",
    "                print(\"Example: \")\n",
    "\n",
    "                print(\"Real:      \" + make_pred(y_batch[0], len_batch[0], class_table))\n",
    "                print(\"Predicted: \" + make_pred(prediction[0], len_batch[0], class_table))\n",
    "                \n",
    "                print(\"Loss: \" + str(c))\n",
    "                \n",
    "        print(\"Epoch {} done! Average loss: \".format(str(e)) + str(avg_loss / num_iter))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
