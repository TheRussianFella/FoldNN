{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    with open(path) as f:\n",
    "        a = f.readlines()\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(dir_path):\n",
    "    data = []; names = []\n",
    "    \n",
    "    for f in set(list(map(lambda x: \".\".join(x.split('.')[:-1]), os.listdir(dir_path)))):\n",
    "        names.append(f)\n",
    "        dssp = read_file(os.path.join(dir_path, f+\".dssp\"))[1].strip(\"\\n\")\n",
    "        fasta = read_file(os.path.join(dir_path, f+\".fasta\"))[1].strip(\"\\n\")\n",
    "        data.append([fasta, dssp])\n",
    "        \n",
    "    return np.array(data), np.array(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, tr_names = load_data(\"train/\")\n",
    "\n",
    "test, test_names = load_data(\"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'RKLKTLPPTLRDKNRYIAFEIISDGDFTKDEVKELIWKSSLEVLGETGTAIVKPWLIKFDPNTKTGIVRSDREYVEYLRFALMLVSEFNGKRLIIRTLGVSGTIKRLKRKFLAKYGWK',\n",
       "       '-------------EEEEEEEEE------HHHHHHHHHHHHHHHHHHHHHHHH--EEEEEE----EEEEEEE---HHHHHHHHH---EE--EE-EEEEEEEE--HHHHHHHH-------'],\n",
       "      dtype='<U759')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#acid_table = list(np.unique(list(\"\".join(train[:,0]))))\n",
    "\n",
    "#class_table = list(np.unique(list(\"\".join(train[:,1]))))\n",
    "\n",
    "acid_table = list(np.load('acid.npz.npy'))\n",
    "class_table = list(np.load('class.npz.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('acid.npz', np.array(acid_table))\n",
    "np.save('class.npz', np.array(class_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_data(data, acid_table, class_table):\n",
    "    \n",
    "    acid_code = lambda x: np.array([acid_table.index(y) for y in x])\n",
    "    class_code = lambda x: np.array([class_table.index(y) + 1 for y in x])\n",
    "    \n",
    "    return np.array(list(map(lambda x: [acid_code(x[0]), class_code(x[1])], data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = translate_data(train, acid_table, class_table)\n",
    "\n",
    "test = translate_data(test, acid_table, class_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ array([15,  7,  9,  0, 16, 12,  7,  9,  7, 12,  3, 11, 13, 14, 12, 12,  4,\n",
       "       12, 14, 15, 17,  5,  8, 17,  7, 14, 15,  3,  5, 16,  3,  5,  0,  8,\n",
       "        4, 14,  9, 15,  5,  8,  5, 17,  2, 13,  2, 12,  8,  5,  7,  4, 14,\n",
       "        7, 11,  3,  7, 15,  5,  2, 17, 15, 17, 16, 14, 12,  9,  2, 14,  3,\n",
       "        0,  7,  0, 11, 20,  3,  9,  3, 17,  3, 17, 16,  2,  9, 15,  5,  8,\n",
       "        7,  7,  2,  5, 12, 17, 14,  9,  2,  7, 15, 17,  7,  2]),\n",
       "       array([1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
       "       1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
       "       1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1])], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_seq(seq, maxlen, stride):\n",
    "    seq_len = seq.shape[0]\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    if seq_len < maxlen:\n",
    "        temp.append(seq)\n",
    "        \n",
    "    else:\n",
    "        full_batches = seq_len // maxlen\n",
    "\n",
    "        for i in range(full_batches):\n",
    "            idx = slice(i * maxlen, (i+1) * maxlen)\n",
    "            temp.append(seq[idx])\n",
    "        \n",
    "        elements_left = seq_len % maxlen\n",
    "        \n",
    "        if elements_left:\n",
    "            start_element = elements_left + stride\n",
    "            \n",
    "            if start_element > maxlen:\n",
    "                start_element = maxlen\n",
    "                \n",
    "            temp.append(seq[-start_element:])\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_pair_seq(pair_seq, maxlen, stride):\n",
    "        \n",
    "    assert pair_seq[0].shape == pair_seq[1].shape\n",
    "\n",
    "    return list(map(list, zip(split_seq(pair_seq[0], maxlen, stride), split_seq(pair_seq[1], maxlen, stride))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_prediction(part_predictions, original_length, stride):\n",
    "    max_len = part_predictions.shape[1]\n",
    "    \n",
    "    final_prediction = []\n",
    "    \n",
    "    if len(part_predictions) != 1:\n",
    "        final_prediction = np.concatenate(part_predictions[:-1], axis=0)\n",
    "\n",
    "    el_left = original_length % max_len\n",
    "    start_element = stride\n",
    "    \n",
    "    if el_left + stride > max_len:\n",
    "        start_element = max_len - el_left\n",
    "\n",
    "    final_part_prediction = part_predictions[-1][start_element:start_element + el_left]\n",
    "\n",
    "    final_prediction = np.concatenate([final_prediction, final_part_prediction], axis=0)\n",
    "    \n",
    "    return final_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(x, session, method, maxlen=400, stride=100):\n",
    "    prepared = []; idx = []; original_len = []; model_len = []\n",
    "    \n",
    "    curr_idx = 0\n",
    "    \n",
    "    for seq in x:\n",
    "        original_len.append(len(seq))\n",
    "        \n",
    "        splited = split_seq(seq, maxlen, stride)\n",
    "        \n",
    "        model_len.extend(list(map(len, splited)))\n",
    "        splited = sequence.pad_sequences(splited, maxlen, value=-1, padding=\"post\")\n",
    "        \n",
    "        prepared.extend(splited)\n",
    "        idx.append([curr_idx, curr_idx+len(splited)])\n",
    "        curr_idx += len(splited)\n",
    "    \n",
    "    predictions = session.run(method, feed_dict={\n",
    "        x_raw: np.array(prepared),\n",
    "        seq_len: np.array(model_len)\n",
    "    })\n",
    "    \n",
    "    final_predictions = []\n",
    "    for i, seq_idx in enumerate(idx):\n",
    "        seq_predictions = predictions[slice(seq_idx[0], seq_idx[1])]\n",
    "\n",
    "        final_predictions.append(build_prediction(seq_predictions, original_len[i], stride))\n",
    "        \n",
    "    return np.array(list(map(lambda x:make_pred(x, len(x), class_table), final_predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(x, y, session, method, maxlen=400, stride=100):\n",
    "    y_pred = predict(x, session, method)\n",
    "    y_pred = list(map(lambda x: list(map(lambda z: class_table.index(z) + 1, x)), y_pred))\n",
    "    return np.mean([accuracy_score(y[i], y_pred[i]) for i in range(len(y))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc_score(y_true, y_pred):\n",
    "    y_pred = list(map(lambda x: list(map(lambda z: class_table.index(z) + 1, x)), y_pred))\n",
    "    return np.mean([accuracy_score(y_true[i], y_pred[i]) for i in range(len(y_true))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def to_normal(seq, seq_len, table):\n",
    "    #print(seq)\n",
    "    return \"\".join(list(map(lambda x: table[int(x)], seq)))[:seq_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_pred(pred_raw, seq_len, table):\n",
    "    pred = pred_raw - 1\n",
    "    pred = np.array(list(map(lambda x: 0 if x == -1 else x, pred)))\n",
    "    return to_normal(pred, seq_len, table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def dynamic_iter(data, batchsize, maxlen=300, stride=100, shuffle=True):\n",
    "    \n",
    "    splited = list(map(lambda x: split_pair_seq(x, maxlen, stride), data))\n",
    "    \n",
    "    prep_data = []\n",
    "    \n",
    "    for seq in splited:\n",
    "        prep_data.extend(seq)\n",
    "    \n",
    "    prep_data = np.array(prep_data)\n",
    "    \n",
    "    # Batching\n",
    "    index = list(range(len(prep_data)))\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.shuffle(index)\n",
    "    for i in range(0, len(prep_data) - batchsize + 1, batchsize):\n",
    "        \n",
    "        x = prep_data[index[i:i+batchsize], 0]\n",
    "        y = prep_data[index[i:i+batchsize], 1]\n",
    "\n",
    "        seq_len = np.array(list(map(lambda z: 400 if len(z) > 400 else len(z), x)), dtype=\"int32\")\n",
    "        \n",
    "        x = sequence.pad_sequences(x, padding=\"post\", value=-1, maxlen=maxlen)\n",
    "        y = sequence.pad_sequences(y, padding=\"post\", maxlen=maxlen)\n",
    "        \n",
    "        yield x, y, seq_len\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_class = len(acid_table)\n",
    "output_class = len(class_table) + 1 # plus one for padding\n",
    "\n",
    "learning_rate = 0.01\n",
    "seq_max_len = 400\n",
    "n_units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_raw = tf.placeholder(tf.int32, [None, seq_max_len], name=\"x_raw\")\n",
    "y_raw = tf.placeholder(tf.int32, [None, seq_max_len], name=\"y_raw\")\n",
    "seq_len = tf.placeholder(tf.int32, [None], name=\"seq_len\")\n",
    "\n",
    "x = tf.one_hot(x_raw, input_class, dtype=tf.float32, name=\"one_hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell(reuse=tf.get_variable_scope().reuse):\n",
    "    cell = tf.contrib.rnn.LSTMCell(n_units, reuse=reuse)\n",
    "    return tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw_cell = lstm_cell(); bw_cell = lstm_cell()\n",
    "\n",
    "output, state = tf.nn.bidirectional_dynamic_rnn(fw_cell, bw_cell, x, seq_len, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con_out = tf.concat(output, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten = tf.reshape(con_out, [-1, 2 * n_units * seq_max_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1_num_units = int(np.mean([2 * n_units * seq_max_len, output_class * seq_max_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"h1\"  : tf.Variable(tf.truncated_normal(shape=[2 * n_units * seq_max_len, h1_num_units], stddev=0.1)),\n",
    "    \"out\" : tf.Variable(tf.truncated_normal(shape=[h1_num_units, output_class * seq_max_len], stddev=0.1))\n",
    "}\n",
    "bias = {\n",
    "    \"h1\"  : tf.Variable(tf.truncated_normal(shape=[h1_num_units])),\n",
    "    \"out\" : tf.Variable(tf.truncated_normal(shape=[output_class * seq_max_len]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1 = tf.nn.relu(tf.matmul(flatten, weights[\"h1\"]) + bias[\"h1\"])\n",
    "flat_logits = tf.matmul(h1, weights[\"out\"]) + bias[\"out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = tf.reshape(flat_logits, shape=[-1, seq_max_len, output_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_raw, logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = tf.to_float(tf.not_equal(y_raw, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_loss = loss * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = tf.nn.l2_loss(weights['h1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_loss = tf.reduce_mean(tf.reduce_sum(norm_loss) / tf.to_float(seq_len) + l2_reg * beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.arg_max(tf.nn.softmax(logits), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 50\n",
    "disp_batch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        avg_loss = 0.; num_iter = 0\n",
    "        for x_batch, y_batch, len_batch in dynamic_iter(train, batch_size, maxlen=seq_max_len):\n",
    "            \n",
    "            _, c = sess.run([train_step, mean_loss], feed_dict={\n",
    "                x_raw: x_batch,\n",
    "                y_raw: y_batch,\n",
    "                seq_len: len_batch\n",
    "            })\n",
    "            \n",
    "            num_iter += 1; avg_loss += c\n",
    "            \n",
    "            if num_iter % disp_batch == 0:\n",
    "                \n",
    "                test_pred = predict(test[:, 0], sess, pred)\n",
    "                \n",
    "                print(\"Batch {}\".format(num_iter))\n",
    "                print(\"Example: \")\n",
    "                \n",
    "                dem_idx = np.random.randint(0, len(test))\n",
    "                \n",
    "                print(\"Real:      \" + make_pred(test[dem_idx, 1], len(test[dem_idx, 1]), class_table))\n",
    "                \n",
    "                print(\"Predicted: \" + test_pred[dem_idx])\n",
    "                \n",
    "                score = acc_score(test[:, 1], test_pred)\n",
    "                \n",
    "                print(\"Accuracy: \" + str(score))\n",
    "                \n",
    "        print(\"Epoch {} done! Average loss: \".format(str(e)) + str(avg_loss / num_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82065223269391485"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_net_pred = []\n",
    "for name in test_names:\n",
    "    j_net_pred.append(\"\".join(read_file(os.path.join(\"JNet_data/\", name+\".jnet\"))[1].strip(\"\\njnetpred:\").split(\",\")))\n",
    "\n",
    "acc_score(test[:, 1], j_net_pred)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
